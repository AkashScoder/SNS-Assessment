{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_UnlUcWFkIy",
        "outputId": "1a177a4e-662c-42de-bf57-521be6a33722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens (Features):\n",
            " ['analytic' 'application' 'behavior' 'career' 'coimbatore' 'communication'\n",
            " 'computer' 'course' 'datum' 'education' 'engineering' 'field' 'focus'\n",
            " 'impact' 'include' 'industry' 'institution' 'intelligence' 'know'\n",
            " 'management' 'marketing' 'medium' 'networking' 'offer' 'platform'\n",
            " 'prepare' 'program' 'provide' 'range' 'relate' 'research' 'science'\n",
            " 'service' 'sns' 'student' 'support' 'technology' 'tie' 'up']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def preprocess_and_tokenize_advanced(text, lemmatize=True, remove_entities=False, pos_filter=None):\n",
        "    \"\"\"\n",
        "    Preprocess and tokenize the input text with advanced options.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text to preprocess and tokenize.\n",
        "    lemmatize (bool): If True, apply lemmatization (default: True).\n",
        "    remove_entities (bool): If True, remove named entities (default: False).\n",
        "    pos_filter (list): List of POS tags to keep, if provided (default: None).\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of clean tokens.\n",
        "    \"\"\"\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Process the text using spaCy NLP pipeline\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        # Exclude stop words, punctuation, and spaces\n",
        "        if token.is_stop or token.is_punct or token.is_space:\n",
        "            continue\n",
        "\n",
        "        # Exclude named entities if specified\n",
        "        if remove_entities and token.ent_type_:\n",
        "            continue\n",
        "\n",
        "        # Apply part-of-speech filtering if specified\n",
        "        if pos_filter and token.pos_ not in pos_filter:\n",
        "            continue\n",
        "\n",
        "        # Apply lemmatization if enabled\n",
        "        if lemmatize:\n",
        "            tokens.append(token.lemma_)\n",
        "        else:\n",
        "            tokens.append(token.text)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def tokenize_and_join(text, lemmatize=True, remove_entities=False, pos_filter=None):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text and joins the tokens into a single string for vectorization.\n",
        "\n",
        "    Returns:\n",
        "    str: A string of clean tokens joined by space.\n",
        "    \"\"\"\n",
        "    tokens = preprocess_and_tokenize_advanced(text, lemmatize, remove_entities, pos_filter)\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Sample text corpus\n",
        "corpus = [\n",
        "    \"SNS Institutions in Coimbatore provide a wide range of educational programs related to digital technologies, including Social Networking Services (SNS).\",\n",
        "    \"The SNS College of Technology offers specialized courses in Computer Science, Artificial Intelligence, and Social Media Analytics, focusing on practical applications in SNS platforms.\",\n",
        "    \"With strong industry tie-ups, SNS College of Engineering in Coimbatore supports research in social media platforms and their impact on communication, marketing, and digital behavior.\",\n",
        "    \"Coimbatore's SNS Institutions are known for their focus on innovative digital education, preparing students for careers in fields such as social media management, digital marketing, and data science.\"\n",
        "]\n",
        "\n",
        "\n",
        "# Preprocess and tokenize the corpus\n",
        "processed_corpus = [tokenize_and_join(text, lemmatize=True, remove_entities=True, pos_filter=['NOUN', 'VERB']) for text in corpus]\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the corpus into a TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_corpus)\n",
        "\n",
        "# Get feature names (tokens)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert TF-IDF matrix to dense format (for readability) and print it\n",
        "dense_matrix = tfidf_matrix.todense()\n",
        "\n",
        "# Display the TF-IDF matrix and the tokens (features)\n",
        "# print(\"TF-IDF Matrix:\\n\", dense_matrix)\n",
        "print(\"Tokens (Features):\\n\", feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fZmMPtT0FoUC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqFnqpvdJ6oJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}